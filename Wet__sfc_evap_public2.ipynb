{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the site data including measurement height, canopy height, latitude, longitude, and IGBP land cover class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site_name</th>\n",
       "      <th>IGBP</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Year</th>\n",
       "      <th>M_height</th>\n",
       "      <th>C_height</th>\n",
       "      <th>a</th>\n",
       "      <th>balance</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CN-Gebi.</td>\n",
       "      <td>BSV</td>\n",
       "      <td>42.001</td>\n",
       "      <td>101.137</td>\n",
       "      <td>2014</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.45</td>\n",
       "      <td>0.83</td>\n",
       "      <td>15.40</td>\n",
       "      <td>22.83</td>\n",
       "      <td>24.70</td>\n",
       "      <td>15.48</td>\n",
       "      <td>0.54</td>\n",
       "      <td>3.91</td>\n",
       "      <td>17.09</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CN-Shens</td>\n",
       "      <td>BSV</td>\n",
       "      <td>38.789</td>\n",
       "      <td>100.493</td>\n",
       "      <td>2014</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.70</td>\n",
       "      <td>0.80</td>\n",
       "      <td>15.97</td>\n",
       "      <td>22.71</td>\n",
       "      <td>21.42</td>\n",
       "      <td>15.98</td>\n",
       "      <td>2.85</td>\n",
       "      <td>8.57</td>\n",
       "      <td>16.43</td>\n",
       "      <td>1.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BE-Lon</td>\n",
       "      <td>CRO</td>\n",
       "      <td>50.552</td>\n",
       "      <td>4.746</td>\n",
       "      <td>2004~2014</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>20.91</td>\n",
       "      <td>0.80</td>\n",
       "      <td>14.23</td>\n",
       "      <td>14.53</td>\n",
       "      <td>15.58</td>\n",
       "      <td>14.23</td>\n",
       "      <td>2.72</td>\n",
       "      <td>0.34</td>\n",
       "      <td>7.45</td>\n",
       "      <td>2.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CN-Daman</td>\n",
       "      <td>CRO</td>\n",
       "      <td>38.856</td>\n",
       "      <td>100.372</td>\n",
       "      <td>2014</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.61</td>\n",
       "      <td>0.93</td>\n",
       "      <td>17.60</td>\n",
       "      <td>17.49</td>\n",
       "      <td>14.82</td>\n",
       "      <td>17.76</td>\n",
       "      <td>6.08</td>\n",
       "      <td>5.75</td>\n",
       "      <td>0.13</td>\n",
       "      <td>9.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DE-Geb</td>\n",
       "      <td>CRO</td>\n",
       "      <td>51.100</td>\n",
       "      <td>10.914</td>\n",
       "      <td>2001~2014</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.91</td>\n",
       "      <td>0.92</td>\n",
       "      <td>18.38</td>\n",
       "      <td>18.29</td>\n",
       "      <td>19.48</td>\n",
       "      <td>18.82</td>\n",
       "      <td>5.44</td>\n",
       "      <td>4.23</td>\n",
       "      <td>9.45</td>\n",
       "      <td>10.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Site_name IGBP     Lat      Lon       Year  ...      f     g     h      i      j\n",
       "0  CN-Gebi.  BSV  42.001  101.137       2014  ...  15.48  0.54  3.91  17.09   0.53\n",
       "1  CN-Shens  BSV  38.789  100.493       2014  ...  15.98  2.85  8.57  16.43   1.91\n",
       "2    BE-Lon  CRO  50.552    4.746  2004~2014  ...  14.23  2.72  0.34   7.45   2.89\n",
       "3  CN-Daman  CRO  38.856  100.372       2014  ...  17.76  6.08  5.75   0.13   9.27\n",
       "4    DE-Geb  CRO  51.100   10.914  2001~2014  ...  18.82  5.44  4.23   9.45  10.20\n",
       "\n",
       "[5 rows x 17 columns]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "info = pd.read_csv('Fluxnet_measurement_canopy_heights.csv')\n",
    "info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the data from all the fluxnet sites in the project. Also, filter the data to remove some obviously erroneous values. Data are loaded into a dataframe, and then this is concatenated with the site-information dataframe from the first step. Now the DataFrame df contains all the usable data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9980\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>TA_F</th>\n",
       "      <th>VPD_F</th>\n",
       "      <th>PA_F</th>\n",
       "      <th>WS_F</th>\n",
       "      <th>NETRAD</th>\n",
       "      <th>G_F_MDS</th>\n",
       "      <th>LE_F_MDS</th>\n",
       "      <th>H_F_MDS</th>\n",
       "      <th>USTAR</th>\n",
       "      <th>SWC_F_MDS_1</th>\n",
       "      <th>LE_F_MDS_QC</th>\n",
       "      <th>Site</th>\n",
       "      <th>IGBP</th>\n",
       "      <th>zt</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>200109</td>\n",
       "      <td>27.570</td>\n",
       "      <td>13.447</td>\n",
       "      <td>100.756</td>\n",
       "      <td>1.342</td>\n",
       "      <td>148.700521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0782</td>\n",
       "      <td>87.9074</td>\n",
       "      <td>0.335391</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.796528</td>\n",
       "      <td>AU-How</td>\n",
       "      <td>WSA</td>\n",
       "      <td>23.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>200111</td>\n",
       "      <td>28.716</td>\n",
       "      <td>7.516</td>\n",
       "      <td>100.504</td>\n",
       "      <td>1.073</td>\n",
       "      <td>170.314583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.4380</td>\n",
       "      <td>41.9754</td>\n",
       "      <td>0.314733</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.998611</td>\n",
       "      <td>AU-How</td>\n",
       "      <td>WSA</td>\n",
       "      <td>23.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>200112</td>\n",
       "      <td>28.249</td>\n",
       "      <td>7.845</td>\n",
       "      <td>100.423</td>\n",
       "      <td>1.248</td>\n",
       "      <td>165.013441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125.9420</td>\n",
       "      <td>33.8638</td>\n",
       "      <td>0.379836</td>\n",
       "      <td>10.8</td>\n",
       "      <td>0.999328</td>\n",
       "      <td>AU-How</td>\n",
       "      <td>WSA</td>\n",
       "      <td>23.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>200208</td>\n",
       "      <td>24.175</td>\n",
       "      <td>15.869</td>\n",
       "      <td>100.852</td>\n",
       "      <td>1.709</td>\n",
       "      <td>127.253767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.2987</td>\n",
       "      <td>70.0827</td>\n",
       "      <td>0.350694</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.740591</td>\n",
       "      <td>AU-How</td>\n",
       "      <td>WSA</td>\n",
       "      <td>23.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>200209</td>\n",
       "      <td>26.403</td>\n",
       "      <td>14.416</td>\n",
       "      <td>100.771</td>\n",
       "      <td>0.921</td>\n",
       "      <td>140.871537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0905</td>\n",
       "      <td>70.9755</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>AU-How</td>\n",
       "      <td>WSA</td>\n",
       "      <td>23.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TIMESTAMP    TA_F   VPD_F     PA_F  ...    Site  IGBP    zt     h\n",
       "8      200109  27.570  13.447  100.756  ...  AU-How   WSA  23.0  15.0\n",
       "10     200111  28.716   7.516  100.504  ...  AU-How   WSA  23.0  15.0\n",
       "11     200112  28.249   7.845  100.423  ...  AU-How   WSA  23.0  15.0\n",
       "19     200208  24.175  15.869  100.852  ...  AU-How   WSA  23.0  15.0\n",
       "20     200209  26.403  14.416  100.771  ...  AU-How   WSA  23.0  15.0\n",
       "\n",
       "[5 rows x 16 columns]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, zipfile\n",
    "import pandas as pd, numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy\n",
    "from scipy.optimize import fsolve\n",
    "from math import sqrt\n",
    "from numpy.lib.scimath import log\n",
    "\n",
    "target='FULLSET_MM'\n",
    "\n",
    "#dir_name = r'D:/My Drive/FLUXNET/'\n",
    "stations = []\n",
    "cover = []\n",
    "data=pd.DataFrame()\n",
    "total_sites=[]\n",
    "for item in os.listdir(): # loop through items in dir\n",
    "    if target in item:   #item is a single site's monthly FULLSET file from fluxnet\n",
    "        site = item[4:10]\n",
    "        total_sites.append(site)\n",
    "        site_df_pre=pd.read_csv(item) ###Reads in the csv with all of \"item\"s data\n",
    "        #Select only the columns we want to keep:  Use TIMESTAMP_START for weekly\n",
    "        site_df_temp=site_df_pre.copy()\n",
    "        if 'SWC_F_MDS_1' not in site_df_temp.columns: #use 'TIMESTAMP_START' for WW. Use \"TIMESTAMP\" otherwise\n",
    "            site_df=site_df_temp[['TIMESTAMP', 'TA_F','VPD_F', 'PA_F', 'WS_F', 'NETRAD','G_F_MDS',\\\n",
    "                             'LE_F_MDS', 'H_F_MDS', 'USTAR']].copy()\n",
    "            site_df['SWC_F_MDS_1']=-9999\n",
    "        else:\n",
    "            site_df=site_df_temp[['TIMESTAMP', 'TA_F','VPD_F', 'PA_F', 'WS_F', 'NETRAD','G_F_MDS',\\\n",
    "                             'LE_F_MDS', 'H_F_MDS', 'USTAR', 'SWC_F_MDS_1', 'LE_F_MDS_QC']].copy()\n",
    "        site_df['G_F_MDS']=np.where(site_df_temp.G_F_MDS>-99, site_df_temp.G_F_MDS, 0)\n",
    "        #site_df=site_df[['TIMESTAMP', 'TA_F','VPD_F', 'PA_F', 'WS_F', 'NETRAD', 'G_F_MDS',\\\n",
    "        #                     'LE_F_MDS', 'H_F_MDS']]\n",
    "        site_df['G_F_MDS']=np.where(site_df.G_F_MDS>-99, site_df.G_F_MDS, 0)\n",
    "        site_df['Site']=site\n",
    "        land_cover=info[info.Site_name==site].IGBP\n",
    "        site_df['IGBP']=land_cover.values[0]\n",
    "        zt=info[info.Site_name==site].M_height\n",
    "        site_df['zt']=zt.values[0]\n",
    "        canop=info[info.Site_name==site].C_height\n",
    "        site_df['h']=canop.values[0]\n",
    "        site_df.replace(-9999, np.nan)\n",
    "        data = pd.concat([data, site_df])\n",
    "data=data[(data.NETRAD - data.G_F_MDS)>0]\n",
    "data=data[data.H_F_MDS>0]\n",
    "data=data[data.LE_F_MDS>0]\n",
    "df=data\n",
    "print(len(df.NETRAD))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make list of all sites that appear in df along with their other characteristics. Put it into a new dataframe, Site_Summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Measure_height (m)</th>\n",
       "      <th>canopy_height (m)</th>\n",
       "      <th>IGBP_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AU-How</td>\n",
       "      <td>-12.494</td>\n",
       "      <td>131.152</td>\n",
       "      <td>23.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>WSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AU-Rig</td>\n",
       "      <td>-36.650</td>\n",
       "      <td>145.576</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>GRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AU-Stp</td>\n",
       "      <td>-17.151</td>\n",
       "      <td>133.350</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>GRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AU-Tum</td>\n",
       "      <td>-35.657</td>\n",
       "      <td>148.152</td>\n",
       "      <td>70.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>EBF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AU-Wac</td>\n",
       "      <td>-37.426</td>\n",
       "      <td>145.188</td>\n",
       "      <td>95.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>EBF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Site     Lat      Lon  Measure_height (m)  canopy_height (m) IGBP_Class\n",
       "0  AU-How -12.494  131.152                23.0               15.0        WSA\n",
       "1  AU-Rig -36.650  145.576                 5.0                0.4        GRA\n",
       "2  AU-Stp -17.151  133.350                 4.2                0.2        GRA\n",
       "3  AU-Tum -35.657  148.152                70.0               40.0        EBF\n",
       "4  AU-Wac -37.426  145.188                95.0               70.0        EBF"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations=pd.unique(df.Site)\n",
    "Lat=[]\n",
    "Lon=[]\n",
    "measure_height=[]\n",
    "canopy_height=[]\n",
    "land_cover=[]\n",
    "Column_names=['Site', 'Lat', 'Lon','Measure_height (m)', 'canopy_height (m)', 'IGBP_Class']\n",
    "for station in stations:\n",
    "    Lat.append(info[info.Site_name==station]['Lat'].values[0])\n",
    "    Lon.append(info[info.Site_name==station]['Lon'].values[0])\n",
    "    measure_height.append(info[info.Site_name==station]['M_height'].values[0])\n",
    "    canopy_height.append(info[info.Site_name==station]['C_height'].values[0])\n",
    "    land_cover.append(info[info.Site_name==station].IGBP.values[0])\n",
    "Site_summary = pd.DataFrame(list(zip(stations, Lat, Lon, measure_height, canopy_height, land_cover)), columns=Column_names)\n",
    "\n",
    "\n",
    "\n",
    "Site_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions needed for the calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estar(T):\n",
    "  #Saturated vapor pressure (Pa) as a function of temp (C)\n",
    "  # formulas from appendix of Andreas et al., 2013\n",
    "  Aw, Bw, Ai, Bi = 17.502, 240.97, 22.452, 272.55 #\n",
    "  estar = np.where(T>=0, 6.1121*1.004*np.exp(Aw*T/(Bw+T)), 6.1115*1.004*np.exp(Ai*T/(Bi+T)))\n",
    "  return estar*100\n",
    "\n",
    "def lv(T):\n",
    "  #Latent heat of vaporization (J/kg) as a funcion of T (C) \n",
    "  #formulas from appendix of Andreas et al., 2013\n",
    "  lv = np.where(T>=0, (25-0.02274*T)*100000, (28.34-0.00149*T)*100000)\n",
    "  return lv\n",
    "\n",
    "def Delta(T):\n",
    "  #Slope of saturated vapor pressure curve at temp T\n",
    "  #formulas from appendix of Andreas et al., 2013\n",
    "  Aw, Bw, Ai, Bi = 17.502, 240.97, 22.452, 272.55\n",
    "  D = np.where(T>=0, estar(T)*(Aw*Bw/(Bw+T)**2), estar(T)*(Ai*Bi/(Bi+T)**2))\n",
    "  return D\n",
    "\n",
    "def LEpenman(Rn, T, fu, ea, gamma):\n",
    "  #Penman evap\n",
    "  D = Delta(T)\n",
    "  return (D/(D+gamma))*Rn+(gamma/(D+gamma))*lv(T)*fu*(estar(T)-ea)\n",
    "\n",
    "def fu_z0(u, zu, zT, Ta, h, c1, c2, c3):\n",
    "    #wind function using MOS theory\n",
    "    z0=h/c1\n",
    "    d0 = c2*h    #z0*0.67/0.1\n",
    "    z0v = z0 / c3\n",
    "    return 0.622 * 0.4**2 * u / (287.04 * (Ta + 273.15) * log((zT - d0) / z0v) * log((zu - d0) / z0))\n",
    "\n",
    "def fu_pen(u, zu, h):\n",
    "  #Wind function using the original penman formulation\n",
    "  u2=u*(2/(zu))**(1/7)\n",
    "  fu=0.26*(1+0.54*u2)/(100*24*60*60)\n",
    "  return fu\n",
    "\n",
    "def mean_abs_error(x,y):\n",
    "    return np.nanmean(np.absolute(x-y))\n",
    "\n",
    "def mean_squared_error(x,y):\n",
    "    return np.mean((x-y)**2)\n",
    "\n",
    "def rmserror(x,y):\n",
    "  return np.sqrt(np.nanmean((x-y)**2))\n",
    "\n",
    "def nse(predictions, targets):\n",
    "    #Nash-Sutcliffe efficiency \n",
    "    return (1-(np.nansum((predictions-targets)**2)/np.nansum((targets-np.nanmean(targets))**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give variables more memorable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['u']=df.WS_F\n",
    "df['Rn_G']=df.NETRAD-df.G_F_MDS\n",
    "df['LEref']=df.Rn_G-df.H_F_MDS #df.Rn_G/(1+df.H_F_MDS/df.LE_F_MDS)     #df.Rn_G-df.Href\n",
    "df['Href']=df.Rn_G-df.LEref\n",
    "df['zu']=df.zt\n",
    "df['zT']=df.zt\n",
    "df['Ta']=df.TA_F+9.81*df.zT/1005\n",
    "df['z0']=df.h*0.123   #df.h*0.123\n",
    "df['d0']=df.h*0.67\n",
    "df['z0v']=df.z0/10  #df.z0*0.1\n",
    "df['p']=df.PA_F*1000\n",
    "df['ea']=estar(df.Ta)-df.VPD_F*100\n",
    "cp=1005\n",
    "eps=0.622\n",
    "df['gamma']=cp*df.p/(eps*lv(df.Ta))\n",
    "df['Lv']=lv(df.Ta)\n",
    "df['DeltaTa']=Delta(df.Ta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fu'] =fu_z0(df.u, df.zu, df.zT, df.Ta, df.h, 8, .67, 10)\n",
    "df['Ep']=LEpenman(df.Rn_G, df.Ta, df.fu, df.ea, df.gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve numerically (using fsolve) for the wet surface ground temperature T0. This is done with a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rcrago\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-clone-2\\lib\\site-packages\\scipy\\optimize\\minpack.py:175: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last ten iterations.\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "T0pz0_trial = np.zeros((len(df.u)))\n",
    "for n in range(len(df.u)):\n",
    "    def Twspz0(Ts):\n",
    "        return df['Rn_G'].values[n]/df['Ep'].values[n]-1\\\n",
    "            -df['gamma'].values[n]*(Ts-df['Ta'].values[n])*(estar(df['Ta'].values[n])-df['ea'].values[n])\n",
    "    T0pz0_trial[n]=fsolve(Twspz0, df['Ta'].values[0])\n",
    "df['T0']=T0pz0_trial\n",
    "df.T0=np.where(df.T0 > df.Ta, df.T0, df.Ta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Ee']=df.Rn_G * Delta(df.T0) / (Delta(df.T0) + df.gamma)\n",
    "df['Tdry'] = df.Ta + df.ea / df.gamma\n",
    "df['Ddry'] = Delta(df.Tdry)\n",
    "df['Emax']=(df.Ddry/(df.Ddry+df.gamma))*df.Rn_G + (df.gamma/(df.Ddry+df.gamma))*lv(df.Ta)*df.fu*estar(df.Tdry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out all non-saturated surfaces using LEref>0.9*LEp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wet surface months:  430\n",
      "Number of sites with wet surface evaporation:  50\n",
      "wet surface cover classes ['GRA' 'CRO' 'ENF' 'OSH' 'DBF' 'WET' 'EBF']\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "df_wet = df[df.LEref/df.Ep>.90]    # Epfu, Epz0,E0w\n",
    "pd.unique(df_wet['IGBP'])\n",
    "print('wet surface months: ', len(df_wet.Site))\n",
    "print('Number of sites with wet surface evaporation: ', len(df_wet.Site.unique()))\n",
    "print('wet surface cover classes', df_wet.IGBP.unique())\n",
    "print(len(df_wet.Site.unique()))\n",
    "wet_sites = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make graphs showing different thresholds for wet surface evaporation. These graphs show that T=0.90 is a good compromise--there are still a large number of points, but LE is very close to LEp for these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "ranges=[[.95, 1.05], [0.9, 1.1], [0.85, 1.15], [0.95, 10], [0.9,10], [0.85, 10]]\n",
    "ranges2=[[.95, 1.05], [0.9, 1.1], [0.85, 1.15], [0.95, '-'], [0.9, \"-\"], [0.85, '-']]\n",
    "fig, axs = plt.subplots(3,2,sharex=True, sharey=True)\n",
    "fig.set_figheight(12)\n",
    "fig.set_figwidth(12)\n",
    "pt_size=5\n",
    "for row in range(3): # is the row\n",
    "    for col in range(2):\n",
    "        dftrial=df.copy()\n",
    "        dftrial=dftrial[(dftrial.LEref/dftrial.Ep>ranges[row+3*col][0]) & (dftrial.LEref/dftrial.Ep<ranges[row+3*col][1])]\n",
    "        x=dftrial.LEref\n",
    "        y=dftrial.Ep\n",
    "        axs[row,col].scatter(x,y, s= pt_size, c='black')\n",
    "        axs[row,col].plot([0,250], [0,250], c='red', linestyle='dashed')\n",
    "        s1, int1, r1, p1, se1 = linregress(x, y)\n",
    "        axs[row,col].plot((5,250),(s1*5+int1, s1*250+int1), c= 'blue', linestyle='dotted')\n",
    "        axs[row, col].set_xlabel('LE$_r$$_e$$_f$ W m$^-$$^2$')\n",
    "        axs[row,col].set_ylabel('LE$_p$ W m$^-$$^2$')\n",
    "        axs[row,col].set_xlim([0,275])\n",
    "        axs[row,col].set_ylim([0,275])\n",
    "        text0='panel '+ str(2*row+col+1)\n",
    "        text1= 'range=' + str(ranges2[row+3*col]) + '; RMSD='+ str(round(rmserror(x,y),3)) \n",
    "        text2= \"S=\"+ str(round(s1, 3))+ '; I='+str(round(int1,3)) + \"; R=\" + str(round(r1,3))+'; SE='+str(round(se1,3))\n",
    "        text3= \"NSE=\" + str(round(nse(x,y),3))+'; Number of points=' + str(round(len(x)))\n",
    "        s=9.5\n",
    "        axs[row,col].text(5,260, text0, fontsize=s)\n",
    "        axs[row,col].text(5,240, text1, fontsize=s)\n",
    "        axs[row,col].text(5,220,text2, fontsize=s)\n",
    "        axs[row,col].text(5,200,text3, fontsize=s)\n",
    "plt.show()    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to map the sites that have at least one measurement that qualifies as wet surface, and also to map all the other sites (with no wet surface measurements) we need lists of these sites along with their latitude and longitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "nonwet_sites_lat=[]\n",
    "nonwet_sites_lon=[]\n",
    "wet_sites_lat=[]\n",
    "wet_sites_lon=[]\n",
    "for n, station in enumerate(stations):\n",
    "    Site_latitude = Site_summary[Site_summary['Site']==station]['Lat'].values.tolist()[0]\n",
    "    Site_longitude = Site_summary[Site_summary['Site']==station]['Lon'].values.tolist()[0]\n",
    "    if station in df_wet.Site.unique():\n",
    "        wet_sites_lat.append(Site_latitude)\n",
    "        wet_sites_lon.append(Site_longitude)\n",
    "    else:\n",
    "        nonwet_sites_lat.append(Site_latitude)\n",
    "        nonwet_sites_lon.append(Site_longitude)\n",
    "print(len(nonwet_sites_lon))\n",
    "print(len(wet_sites_lon))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot sites with some wet surface values and then plot sites with no wet surface values. Note that geopandas is not part of the normal python istallation, so it is installed using pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopandas in c:\\users\\rcrago\\appdata\\local\\esri\\conda\\envs\\arcgispro-py3-clone-2\\lib\\site-packages (0.8.1)\n",
      "Requirement already satisfied: shapely in c:\\users\\rcrago\\appdata\\local\\esri\\conda\\envs\\arcgispro-py3-clone-2\\lib\\site-packages (from geopandas) (1.7.1)\n",
      "Requirement already satisfied: pandas>=0.23.0 in c:\\users\\rcrago\\appdata\\local\\esri\\conda\\envs\\arcgispro-py3-clone-2\\lib\\site-packages (from geopandas) (1.3.5)\n",
      "Requirement already satisfied: fiona in c:\\users\\rcrago\\appdata\\local\\esri\\conda\\envs\\arcgispro-py3-clone-2\\lib\\site-packages (from geopandas) (1.8.13.post1)\n",
      "Requirement already satisfied: pyproj>=2.2.0 in c:\\users\\rcrago\\appdata\\local\\esri\\conda\\envs\\arcgispro-py3-clone-2\\lib\\site-packages (from geopandas) (2.6.1.post1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\rcrago\\appdata\\local\\esri\\conda\\envs\\arcgispro-py3-clone-2\\lib\\site-packages\\pytz-2022.1-py3.7.egg (from pandas>=0.23.0->geopandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\rcrago\\appdata\\local\\esri\\conda\\envs\\arcgispro-py3-clone-2\\lib\\site-packages (from pandas>=0.23.0->geopandas) (1.20.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\rcrago\\appdata\\local\\esri\\conda\\envs\\arcgispro-py3-clone-2\\lib\\site-packages (from pandas>=0.23.0->geopandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rcrago\\appdata\\local\\esri\\conda\\envs\\arcgispro-py3-clone-2\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=0.23.0->geopandas) (1.16.0)\n",
      "Requirement already satisfied: attrs>=17 in c:\\users\\rcrago\\appdata\\local\\esri\\conda\\envs\\arcgispro-py3-clone-2\\lib\\site-packages (from fiona->geopandas) (21.4.0)\n",
      "Requirement already satisfied: click<8,>=4.0 in c:\\users\\rcrago\\appdata\\local\\esri\\conda\\envs\\arcgispro-py3-clone-2\\lib\\site-packages (from fiona->geopandas) (7.1.2)\n",
      "Requirement already satisfied: cligj>=0.5 in c:\\users\\rcrago\\appdata\\local\\esri\\conda\\envs\\arcgispro-py3-clone-2\\lib\\site-packages (from fiona->geopandas) (0.7.2)\n",
      "Requirement already satisfied: click-plugins>=1.0 in c:\\users\\rcrago\\appdata\\local\\esri\\conda\\envs\\arcgispro-py3-clone-2\\lib\\site-packages (from fiona->geopandas) (1.1.1)\n",
      "Requirement already satisfied: munch in c:\\users\\rcrago\\appdata\\local\\esri\\conda\\envs\\arcgispro-py3-clone-2\\lib\\site-packages (from fiona->geopandas) (2.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install geopandas\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from geopandas import GeoDataFrame\n",
    "\n",
    "geometry_wet = [Point(xy) for xy in zip(wet_sites_lon, wet_sites_lat)]\n",
    "geometry_dry = [Point(xy) for xy in zip(nonwet_sites_lon, nonwet_sites_lat)]\n",
    "gdfwet=GeoDataFrame(geometry=geometry_wet)\n",
    "gdfdry=GeoDataFrame(geometry=geometry_dry)\n",
    "world=gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "gdfwet.plot(ax=world.plot(figsize=(10,10), color='tan'), marker='o', color='blue', markersize=15)\n",
    "gdfdry.plot(ax=world.plot(figsize=(10,10), color='tan'), marker='o', color='red', markersize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a process to find tuned parameters for alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "import random\n",
    "\n",
    "E=df_wet.LEref\n",
    "R=df_wet.Rn_G\n",
    "T=df_wet.T0  #df_wet.T0w  #df_wet.T0pz0  #df_wet.T0pfu\n",
    "g=df_wet.gamma\n",
    "fu=df_wet.fu #fuz0  #fupen\n",
    "e_a=df_wet.ea\n",
    "T_a=df_wet.Ta\n",
    "\n",
    "D=Delta(T)\n",
    "Ee=D*R/(D+g)\n",
    "Emax=lv(T)*fu*estar(T)\n",
    "\n",
    "alpha=E*(D+g)/(D*R)\n",
    "\n",
    "rms1best=1000\n",
    "rms2best=1000\n",
    "rms3best=1000\n",
    "rms4best=1000\n",
    "rms5best=1000\n",
    "rms6best=1000\n",
    "rms7best=1000\n",
    "rms8best=2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process to find tuned parameter values--those values that minimze RMSD of alpha or of LEPT. This is found by randomly selecting values in a realistic range for each parameter, finding the RMSD, and selecting the parameter value that gave the lowest RMSD value. 3000 random selections are made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n"
     ]
    }
   ],
   "source": [
    "for n in range(3000):\n",
    "    if n in [10, 500, 1000, 1500, 2000, 2500]: print(n)\n",
    "    RH=random.uniform(0, 1)\n",
    "    aA=random.uniform(0, 1)\n",
    "    alp=random.uniform(1, 1.6)\n",
    "    m_alph=random.uniform(0,1)\n",
    "    alpha_RH = 1 + (g/Delta(T))*lv(T)*fu*estar(T)*(1-RH)/R\n",
    "    alpha_RH = np.where(alpha_RH>(1+g/D), 1+g/D, alpha_RH)\n",
    "    alpha_A=(D+g)/(D+aA*g)\n",
    "    alpha_m=1+g*m_alph/D\n",
    "    LEPT_const=alp*D*R/(D+g)\n",
    "    LEPT_RH=alpha_RH*D*R/(D+g)\n",
    "    LEPT_A=alpha_A*D*R/(D+g)\n",
    "    LEPT_const=alp*D*R/(D+g)\n",
    "    LEPT_m=alpha_m*D*R/(D+g)\n",
    "    alph=np.zeros((len(df_wet.Ta)))+alp\n",
    "    rms1=rmserror(alpha, alpha_RH)\n",
    "    rms2=rmserror(alpha, alpha_A)\n",
    "    rms3=rmserror(alpha,alph)\n",
    "    rms4=rmserror(alpha,alpha_m)\n",
    "    rms5=rmserror(E, LEPT_RH)\n",
    "    rms6=rmserror(E, LEPT_A)\n",
    "    rms7=rmserror(E, LEPT_const)\n",
    "    rms8=rmserror(E, LEPT_m)\n",
    "    \n",
    "    \n",
    "    if rms1 < rms1best:#alpha_RH \n",
    "        rms1best=rms1\n",
    "        RH_best=RH\n",
    "    if rms2 <rms2best: #alpha_A\n",
    "        rms2best=rms2\n",
    "        aA_best=aA\n",
    "    if rms3<rms3best: #alpha_c\n",
    "        rms3best=rms3\n",
    "        alp_best=alp\n",
    "    if rms4<rms4best: #alpha_m\n",
    "        rms4best=rms4\n",
    "        m_best=m_alph\n",
    "    if rms5<rms5best: #LEPT_RH\n",
    "        rms5best=rms5\n",
    "        RH_Ebest=RH  \n",
    "    if rms6<rms6best: #LEPT_Andreas\n",
    "        rms6best=rms6 \n",
    "        aA_Ebest=aA\n",
    "    if rms7<rms7best: #LEPT_alpha_const\n",
    "        rms7best=rms7\n",
    "        alp_Ebest=alp\n",
    "    if rms8<rms8best: #LEPT_m\n",
    "        rms8best=rms8\n",
    "        m_Ebest=m_alph\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plots of model performace with the tuned parameters, along with performance statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_RH = 1 + (g/D)*lv(T)*fu*estar(T)*(1-RH_best)/R\n",
    "alpha_RH = np.where(alpha_RH>(1+g/D), 1+g/D, alpha_RH)\n",
    "alpha_A=(D+g)/(D+aA_best*g)\n",
    "alpha_m=1+g*m_best/D\n",
    "alpha_RH_E = 1 + (g/D)*lv(T)*fu*estar(T)*(1-RH_Ebest)/R\n",
    "alpha_RH_E=np.where(alpha_RH_E > 1+g/D, 1+g/D, alpha_RH_E)\n",
    "LEPT_RH= alpha_RH_E*D*R/(D+g)\n",
    "LEPT_A = ((D+g)/(D+aA_Ebest*g))*D*R/(D+g)\n",
    "LEPT_alphabest =alp_Ebest*D*R/(D+g)\n",
    "LEPT_mbest = (1+g*m_Ebest/D)*D*R/(D+g)\n",
    "\n",
    "x1=alpha\n",
    "y1=alpha_RH\n",
    "x2=alpha\n",
    "y2=alpha_A\n",
    "x3=alpha\n",
    "y3=alp_best*alpha/alpha\n",
    "x4=alpha\n",
    "y4=alpha_m\n",
    "s1, int1, r1, p1, se1 = linregress(x1, y1) \n",
    "s2, int2, r2, p2, se2 = linregress(x2, y2)       \n",
    "s3, int3, r3, p3, se3 =linregress(x3, y3)\n",
    "s4, int4, r4, p4, se4 =linregress(x4, y4)\n",
    "NSE1, NSE2, NSE3, NSE4 = nse(x1, y1), nse(x2, y2), nse(x3, y3), nse(x4, y4)\n",
    "#print(np.max(y2-y3))\n",
    "\n",
    "x5=E\n",
    "y5=LEPT_RH\n",
    "x6=E\n",
    "y6=LEPT_A\n",
    "x7=E\n",
    "y7=LEPT_alphabest\n",
    "x8=E\n",
    "y8=LEPT_mbest\n",
    "s5, int5, r5, p5, se5 = linregress(x5, y5)\n",
    "s6, int6, r6, p6, se6 = linregress(x6, y6)\n",
    "s7, int7, r7, p7, se7 = linregress(x7, y7)\n",
    "s8, int8, r8, p8, se8 = linregress(x8, y8)\n",
    "NSE5, NSE6, NSE7, NSE8 = nse(x5, y5), nse(x6, y6), nse(x7, y7), nse(x8, y8)\n",
    "\n",
    "text1 = \"RH-method: \" + 'RH='+ str(round(RH_best, 2)) + '; RMSD=' + str(round(rmserror(x1, y1), 2))\\\n",
    "        + '; R=' + str(round(r1, 2)) + '; S='+str(round(s1, 2))+'; I=' + str(round(int1, 2))+\"; NSE=\"+str(round(NSE1,2))\n",
    "text2 = 'a$_A$-method: '+'a$_A$=' + str(round(aA_best, 2))+'; RMSD='+str(round(rmserror(x2,y2),2))\\\n",
    "        +'; R='+ str(round(r2,2))+'; S='+str(round(s2,2))+'; I='+str(round(int2, 2))+\"; NSE=\"+str(round(NSE2,2))\n",
    "text3 = r'$\\alpha$$_c$-method: '+'alpha=' + str(round(alp_best, 2))+'; RMSD='+str(round(rmserror(x3,y3),2))\\\n",
    "        +'; R=0 ;'+ 'S='+'0;'+ 'I='+str(round(int3, 2))+\"; NSE=0\"\n",
    "text4 = 'm-method: ''m =' + str(round(m_best, 2))+'; RMSD='+str(round(rmserror(x4,y4),2))\\\n",
    "        +'; R='+ str(round(r4,2))+'; S='+str(round(s4,2))+'; I='+str(round(int4, 2))+\"; NSE=\"+str(round(NSE4,2))\n",
    "text5 = \"RH-method: \" + 'RH = '+ str(round(RH_Ebest, 2)) + '; RMSD= ' + str(round(rmserror(x5, y5), 2)) + ' W/m$^2$'\\\n",
    "        + '; R = ' + str(round(r5, 2)) + '; S= ' + str(round(s5, 2)) + \"; I= \" + str(round(int5, 2)) + ' W/m$^2$'+\"; NSE=\"+str(round(NSE5,2))\n",
    "text6 = 'a$_A$-method: '+'a$_A$ = ' + str(round(aA_Ebest, 2))+'; RMSD= '+str(round(rmserror(x6,y6),2))+ ' W/m$^2$'\\\n",
    "        +'; R= '+ str(round(r6,2))+'; S= '+str(round(s6,2))+'; I= '+str(round(int6, 2))+ ' W/m$^2$'+\"; NSE=\"+str(round(NSE6,2))  \n",
    "text7 = r'$\\alpha$$_c$-method: '+'alpha = ' + str(round(alp_Ebest, 2))+'; RMSD= '+str(round(rmserror(x7,y7),2))+ ' W/m$^2$'\\\n",
    "        +'; R= '+ str(round(r7,2))+'; S= '+str(round(s7,2))+'; I= '+str(round(int7, 2))+ ' W/m$^2$'+\"; NSE=\"+str(round(NSE7,2))\n",
    "text8 = 'm-method: '+'m = ' + str(round(m_Ebest, 2))+'; RMSD= '+str(round(rmserror(x8,y8),2))+ ' W/m$^2$'\\\n",
    "        +'; R= '+ str(round(r8,2))+'; S= '+str(round(s8,2))+'; I= '+str(round(int8, 2))+ ' W/m$^2$'+\"; NSE=\"+str(round(NSE8,2))\n",
    "text9=\"Num=\" + str(len(df_wet.Ta)) #+ '; IGBP=' + str([x for x in pd.unique(df_wet.IGBP)])\n",
    "\n",
    "fs=12\n",
    "msize=20\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2,1)\n",
    "fig.set_figheight(13)\n",
    "fig.set_figwidth(10)\n",
    "plt.rcParams.update({'font.size': fs})\n",
    "\n",
    "ax1.scatter(x1, y1, marker='.', s=msize, c='black', label=r'$\\alpha$$_R$$_H$')\n",
    "ax1.scatter(x2, y2, marker='x', s=msize, c='red', alpha=0.4, label=r'$\\alpha$$_a$$_A$')\n",
    "ax1.scatter(x3,y3, marker=',', s=msize, c='brown', alpha=0.4, label=r'$\\alpha$$_c$')\n",
    "ax1.plot([1, 2.9], [1,2.9], linestyle='solid', c='gray', )\n",
    "ax1.scatter(x4,y4, marker='o', s=msize, c='green', alpha=.2, label=r'$\\alpha$$_m$')\n",
    "ax1.set_xlabel(r'$\\alpha$$_r$$_e$$_f$', fontsize=fs+4)\n",
    "ax1.set_ylabel(r'$\\alpha$$_e$$_s$$_t$', fontsize=fs+4)\n",
    "ax1.set_xlim(1,2.5)\n",
    "ax1.set_ylim(1,3.1)\n",
    "ax1.text(1.05, 3.0, text3, fontsize=fs)\n",
    "ax1.text(1.05, 2.9, text2, fontsize=fs)\n",
    "ax1.text(1.05, 2.8, text1, fontsize=fs)\n",
    "ax1.text(1.05, 2.7, text4, fontsize=fs)\n",
    "ax1.text(1.05, 2.6, text9, fontsize=fs)\n",
    "ax1.legend(loc='lower right')\n",
    "\n",
    "ax2.scatter(x5, y5, marker='.', s=msize, c='black', label=r'$\\alpha$$_R$$_H$')\n",
    "ax2.scatter(x6, y6, marker='x', s=msize, c='red', alpha=0.4, label=r'$\\alpha$$_a$$_A$')\n",
    "ax2.scatter(x7, y7, marker=',', s=msize, c='blue', alpha=0.3, label=r'$\\alpha$$_c$')\n",
    "ax2.scatter(x8, y8, marker='o', s=msize, c='green', alpha=0.2, label=r'$\\alpha$$_m$')\n",
    "ax2.plot([1,250], [1,250], c='brown')\n",
    "ax2.set_xlabel('LE$_r$$_e$$_f$ (W/m$^2$)', fontsize=fs+4)\n",
    "ax2.set_ylabel('LE$_P$$_T$ (W/m$^2$)', fontsize=fs+4)\n",
    "ax2.set_xlim(0,250)\n",
    "ax2.set_ylim(0,320)\n",
    "ax2.text(2, 308, text7, fontsize=fs)\n",
    "ax2.text(2,291, text6, fontsize=fs)\n",
    "ax2.text(2,274, text5, fontsize=fs)\n",
    "ax2.text(2,257, text8, fontsize=fs)\n",
    "ax2.text(2,239, text9, fontsize=fs)\n",
    "ax2.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar random trials to get tuned parameter values for estimating LE with the CR. This process is mucn slower because all the data needs to be processed. Good results are obtainable with only 1000 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "__main__:11: RuntimeWarning: divide by zero encountered in true_divide\n",
      "__main__:12: RuntimeWarning: invalid value encountered in add\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "1000\n",
      "2000\n",
      "2500\n",
      "[19.37382413 18.60957412 21.12573829 18.6451736 ]\n",
      "[1.21852597 0.4304562  0.9643579  0.45099669]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats import linregress\n",
    "\n",
    "best_rms=np.zeros((4))+10000\n",
    "best_par=np.zeros((4))\n",
    "LEmodel=np.zeros((4, len(df.Ta)))\n",
    "\n",
    "def yvalues(Sd, Sw, xm, x):\n",
    "  d=(Sd*xm - Sd + Sw*xm - Sw + 2)/(xm**3 - 3*xm**2 + 3*xm - 1)\n",
    "  c=(-Sw*xm + Sw - d*xm**3 + 3*d*xm - 2*d - 1)/(xm**2 - 2*xm + 1)\n",
    "  b=(-c*xm**2 + c - d*xm**3 + d - 1)/(xm - 1)\n",
    "  a=1-(b+c+d)\n",
    "  return a+b*x+c*x**2+d*x**3\n",
    "\n",
    "iterations=3000\n",
    "for a in range(iterations):\n",
    "    if a in [1, 500, 1000, 2000, 2500]:\n",
    "        print(a)\n",
    "    alp=random.uniform(1, 1.6)\n",
    "    aA=random.uniform(0, 1)\n",
    "    RH=random.uniform(0,1)\n",
    "    SD=1#random.uniform(0, 2)\n",
    "    SW=1#random.uniform(0, 2)\n",
    "    M=random.uniform(0, 1)\n",
    "    for a in range(4):\n",
    "        if a==0: #constant alpha\n",
    "            par=alp\n",
    "            alpha=alp\n",
    "            x=alpha*df.Ee/df.Ep\n",
    "            xmin=alp*df.Ee/df.Emax\n",
    "        if a==1: #constant aA\n",
    "            par=aA\n",
    "            alpha=(Delta(df.T0)+df.gamma)/(Delta(df.T0)+aA*df.gamma)\n",
    "            x=alpha*df.Ee/df.Ep\n",
    "            xmin=alpha*df.Ee/df.Emax\n",
    "        if a==2:  #constant RH\n",
    "            par=RH\n",
    "            alpha=1+(df.gamma/Delta(df.T0))*lv(df.Ta)*df.fu*estar(df.T0)*(1-RH)/df.Rn_G\n",
    "            alpha=np.where(alpha>1+df.gamma/Delta(df.T0), 1+df.gamma/Delta(df.T0), alpha)\n",
    "            x=alpha*df.Ee/df.Ep\n",
    "            xmin=alpha*df.Ee/df.Emax\n",
    "        if a==3: #constant M\n",
    "            par=M\n",
    "            alpha=(1+df.gamma*M/Delta(df.T0))\n",
    "            x=alpha*df.Ee/df.Ep\n",
    "            xmin=alpha*df.Ee/df.Emax           \n",
    "        x=np.where(x<0,0.0001,x)\n",
    "        x=np.where(x>1, 1, x)\n",
    "        xmin=np.where(xmin<0, 0.0001, xmin)\n",
    "        xmin=np.where(xmin>x, x, xmin)\n",
    "        LEest=yvalues(SD, SW, xmin, x)*df.Ep\n",
    "        rms=rmserror(df.LEref, LEest)\n",
    "        if rms<best_rms[a]:\n",
    "            best_rms[a]=rms\n",
    "            best_par[a]=par\n",
    "            LEmodel[a,:]=LEest\n",
    "print(best_rms)\n",
    "print(best_par)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal parameter values used in CR estimates of LE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2)\n",
    "fig.set_figheight(15)\n",
    "fig.set_figwidth(15)\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "version_b=[r'$\\alpha$$_c$','a$_A$', 'RH', 'm'] \n",
    "sz=.3\n",
    "for a in range(4):\n",
    "    c1=[0,0,1,1]\n",
    "    c2=[0,1,0,1]\n",
    "    xy=pd.DataFrame(list(zip(df.LEref, LEmodel[a,:],)), columns=['x','y'])\n",
    "    xy=xy.dropna()\n",
    "    axs[c1[a],c2[a]].scatter(xy.x, xy.y, s=sz, c='black')\n",
    "    axs[c1[a],c2[a]].plot([0, 200], [0, 200], c='red', marker=None, linestyle='dashed')\n",
    "    axs[c1[a],c2[a]].set_xlim([0, 210])\n",
    "    axs[c1[a],c2[a]].set_ylim([0,210])\n",
    "    axs[c1[a],c2[a]].set_xlabel('LE$_r$$_e$$_f$ (W/m$^2$)', fontsize=14)\n",
    "    axs[c1[a],c2[a]].set_ylabel('LE$_e$$_s$$_t$ (W/m$^2$)', fontsize=14)\n",
    "    rms=rmserror(xy.x, xy.y)\n",
    "    NSE=nse(xy.x, xy.y)\n",
    "    S, I, R, p1, se1 = linregress(xy.x, xy.y)\n",
    "    axs[c1[a],c2[a]].plot((0,200), (S*0+I,  S*200+I), marker=None, c='blue', linestyle='dotted')\n",
    "    text1=version_b[a]+'-method: ' +  version_b[a] +'=' + str(round(best_par[a],2))\n",
    "    text2='RMS' + '='+ str(round(rms,2))+ '(W/m$^2$)'+'; R='+str(round(R,2))\n",
    "    text3 = 'NSE=' + str(round(NSE,2))\n",
    "    text4='Slope=' + str(round(S,2)) + ' Int (W/m$^2$)=' + str(round(I,2))\n",
    "    text5='y=X'+\"; Num=\"+str(len(df.Ta))\n",
    "    panel=['a', 'b', 'c', 'd']\n",
    "    text6 = 'panel '+ str(panel[2*c1[a]+c2[a]])\n",
    "    #text5='SD='+str(SD)+ \"; SW=\" + str(SW)\n",
    "    axs[c1[a],c2[a]].text(1,190, text1)\n",
    "    axs[c1[a],c2[a]].text(1,180, text2)\n",
    "    axs[c1[a],c2[a]].text(1,170, text3)\n",
    "    axs[c1[a],c2[a]].text(1,160, text4)\n",
    "    axs[c1[a],c2[a]].text(1,150, text5)\n",
    "    axs[c1[a],c2[a]].text(1,200, text6)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
